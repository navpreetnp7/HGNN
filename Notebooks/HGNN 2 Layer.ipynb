{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from utils import load_data,svdApprox,nmi_score,normalize\n",
    "#from GNN import GraphNeuralNet\n",
    "import pycombo\n",
    "import networkx as nx\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from layers import GraphNN1, GraphNN1_h, GraphNN2, InnerProduct\n",
    "from utils import doublerelu\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Disables CUDA training.')\n",
    "parser.add_argument('--fastmode', action='store_true', default=False,\n",
    "                    help='Validate during training pass.')\n",
    "parser.add_argument('--seed', type=int, default=426, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=20001,\n",
    "                    help='Number of epochs to train.')\n",
    "parser.add_argument('--lr', type=float, default=0.00001,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--weight_decay', type=float, default=10e-4,\n",
    "                    help='Weight decay (L2 loss on parameters).')\n",
    "parser.add_argument('--hidden', type=int, default=16,\n",
    "                    help='Number of hidden units.')\n",
    "parser.add_argument('--ndim', type=int, default=5,\n",
    "                    help='Embeddings dimension.')\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    # Taxi Dataset Graph\n",
    "    adj = load_data()\n",
    "    #adj = load_data(daily=True)\n",
    "else:\n",
    "    #Toy Example Graph\n",
    "    adj = toy_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "class GraphNN1(Module):\n",
    "\n",
    "    def __init__(self, batch_size, in_features, out_features, fixed):\n",
    "        super(GraphNN1, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fixed = fixed\n",
    "        weight0_eye = torch.FloatTensor(torch.eye(in_features,out_features))\n",
    "        weight0_eye = weight0_eye.reshape((1, in_features, out_features))\n",
    "        weight0_eye = weight0_eye.repeat(batch_size, 1, 1)\n",
    "        self.weight0 = Parameter(weight0_eye)\n",
    "        self.weight1 = Parameter(torch.zeros(batch_size, in_features, out_features))\n",
    "\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        v1 = torch.bmm(input, self.weight0)\n",
    "        v2 = torch.bmm(torch.bmm(adj, input),self.weight1)\n",
    "        output = v1 + v2\n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "\n",
    "class GraphNN2(Module):\n",
    "\n",
    "    def __init__(self, batch_size, in_features, out_features, fixed):\n",
    "        super(GraphNN2, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fixed = fixed\n",
    "        weight0_eye = torch.FloatTensor(torch.eye(in_features,in_features))\n",
    "        weight0_eye = weight0_eye.reshape((1, in_features, in_features))\n",
    "        weight0_eye = weight0_eye.repeat(batch_size, 1, 1)\n",
    "        weight0_rand = torch.empty(batch_size,in_features,out_features-in_features)\n",
    "        torch.nn.init.xavier_uniform_(weight0_rand, gain=1.0)\n",
    "        self.weight0 = Parameter(torch.cat((weight0_eye,weight0_rand),dim=2))\n",
    "        self.weight1 = Parameter(torch.zeros(batch_size, in_features, out_features))\n",
    "\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        v1 = torch.bmm(input, self.weight0)\n",
    "        v2 = torch.bmm(torch.bmm(adj, input),self.weight1)\n",
    "        output = v1 + v2\n",
    "        return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN1Layer(nn.Module):\n",
    "\n",
    "    def __init__(self, batch_size, nfeat, hidden, ndim, fixed):\n",
    "        super(GNN1Layer, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.nfeat = nfeat\n",
    "        if fixed:\n",
    "            self.ndim = 2*ndim\n",
    "            self.hidden = hidden\n",
    "        else:\n",
    "            self.ndim = 4*ndim\n",
    "            self.hidden = 2*hidden\n",
    "        self.fixed = fixed\n",
    "\n",
    "        self.x1 = GraphNN1(batch_size, self.ndim, self.ndim, fixed)\n",
    "        #self.x2 = GraphNN1(batch_size, self.hidden*self.ndim, self.ndim, fixed)\n",
    "        \n",
    "        self.reconstructions = InnerProduct(self.ndim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "\n",
    "        #scale weights for sigmoid\n",
    "        scale = 1000\n",
    "        x = x/scale\n",
    "        x = torch.sigmoid(x)\n",
    "        x1 = doublerelu(self.x1(x, adj))\n",
    "        x2 = torch.logit(x1)\n",
    "\n",
    "        # rescale back to original weights\n",
    "        x2 = x2*scale\n",
    "        if self.fixed:\n",
    "            mu = F.relu(self.reconstructions(x2))\n",
    "            return mu, x2\n",
    "        else:\n",
    "            lr1, lr2 = torch.chunk(x2, chunks=2, dim=2)\n",
    "            mu = F.relu(self.reconstructions(lr1))\n",
    "            sigma = F.relu(self.reconstructions(lr2))\n",
    "            return mu, sigma, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN2Layer(nn.Module):\n",
    "\n",
    "    def __init__(self, batch_size, nfeat, hidden, ndim, fixed):\n",
    "        super(GNN2Layer, self).__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.nfeat = nfeat\n",
    "        if fixed:\n",
    "            self.ndim = 2*ndim\n",
    "            self.hidden = hidden\n",
    "        else:\n",
    "            self.ndim = 4*ndim\n",
    "            self.hidden = 2*hidden\n",
    "        self.fixed = fixed\n",
    "\n",
    "        self.x1 = GraphNN2(batch_size, self.ndim, self.hidden*self.ndim, fixed)\n",
    "        self.x2 = GraphNN1(batch_size, self.hidden*self.ndim, self.ndim, fixed)\n",
    "        \n",
    "        self.reconstructions = InnerProduct(self.ndim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "\n",
    "        #scale weights for sigmoid\n",
    "        scale = 1000\n",
    "        x = x/scale\n",
    "        x = torch.sigmoid(x)\n",
    "        x1 = doublerelu(self.x1(x, adj))\n",
    "        x2 = doublerelu(self.x2(x1, adj))\n",
    "        x2 = torch.logit(x2)\n",
    "\n",
    "        # rescale back to original weights\n",
    "        x2 = x2*scale\n",
    "        if self.fixed:\n",
    "            mu = F.relu(self.reconstructions(x2))\n",
    "            return mu, x2\n",
    "        else:\n",
    "            lr1, lr2 = torch.chunk(x2, chunks=2, dim=2)\n",
    "            mu = F.relu(self.reconstructions(lr1))\n",
    "            sigma = F.relu(self.reconstructions(lr2))\n",
    "            return mu, sigma, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GraphNeuralNet(adj,dim,hidden,fixed,features,GNN):\n",
    "\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.cuda:\n",
    "        torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "    adj_norm = normalize(adj)\n",
    "\n",
    "    adj = torch.FloatTensor(np.array(adj))\n",
    "    adj_norm = torch.FloatTensor(np.array(adj_norm))\n",
    "\n",
    "    # loss function\n",
    "    criterion = torch.nn.GaussianNLLLoss()\n",
    "\n",
    "    # NULL Model\n",
    "    mu0 = adj.mean() * torch.ones(adj.shape[1:])\n",
    "    sigma0 = adj.std() * torch.ones(adj.shape[1:])\n",
    "    with torch.no_grad():\n",
    "        loss0 = criterion(torch.flatten(adj), torch.flatten(mu0), torch.flatten(torch.square(sigma0)))\n",
    "\n",
    "    # Model and optimizer\n",
    "\n",
    "    model = GNN(batch_size=adj.shape[0],\n",
    "                nfeat=features.shape[1],\n",
    "                hidden=hidden,\n",
    "                ndim=dim,\n",
    "                fixed=fixed)\n",
    "\n",
    "    if args.cuda:\n",
    "        model = model.cuda()\n",
    "        features = features.cuda()\n",
    "        adj = adj.cuda()\n",
    "        adj_norm = adj_norm.cuda()\n",
    "\n",
    "    # Train model\n",
    "    t_total = time.time()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(),\n",
    "                           lr=args.lr, weight_decay=args.weight_decay)\n",
    "\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if fixed:\n",
    "            mu,lr = model(features, adj_norm)\n",
    "            with torch.no_grad():\n",
    "                mse = torch.nn.MSELoss()\n",
    "                mseloss = mse(torch.flatten(mu), torch.flatten(adj))\n",
    "                sig = torch.sqrt(mseloss)\n",
    "            sigma = sig * torch.ones(adj.shape, requires_grad=True).cuda()\n",
    "        else:\n",
    "            mu, sigma,lr = model(features, adj_norm)\n",
    "\n",
    "        loss = criterion(torch.flatten(adj), torch.flatten(mu), torch.flatten(torch.square(sigma)))\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch == 0:\n",
    "            best_loss = loss\n",
    "            best_lr = lr\n",
    "            best_mu = mu\n",
    "            if fixed:\n",
    "                best_sig = sig\n",
    "        else:\n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_lr = lr\n",
    "                best_mu = mu\n",
    "                if fixed:\n",
    "                    best_sig = sig\n",
    "\n",
    "        if epoch % 5000 == 0:\n",
    "            print('Epoch: {:04d}'.format(epoch + 1),\n",
    "                  'loss: {:.8f}'.format(best_loss.item()),\n",
    "                  'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n",
    "\n",
    "    if fixed:\n",
    "        return best_lr, best_sig, best_mu, best_loss\n",
    "    else:\n",
    "        return best_lr, best_mu, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HGNN(adj,dim,hidden,fixed):\n",
    "    \n",
    "    #partition using pycombo\n",
    "    G = nx.from_numpy_matrix(np.array(adj[0]))\n",
    "    partition = pycombo.execute(G, random_seed = args.seed)\n",
    "    \n",
    "    #get binary matrix of the partition and inverse community disaggregation mapping\n",
    "    nb_community = max(list(partition[0].values())) + 1\n",
    "    communities =  np.array(list(partition[0].values())).reshape(-1)\n",
    "    C = np.eye(nb_community)[communities]\n",
    "    C = torch.Tensor(C).unsqueeze(0)\n",
    "    \n",
    "    #perform svd on orig network\n",
    "    _,sig,_,svd_embedx,svd_embedy = svdApprox(adj,dim)\n",
    "    svd_embed = torch.cat([svd_embedx,svd_embedy],dim=1)\n",
    "    if not fixed:\n",
    "        svd_sigma = torch.ones(svd_embed.shape) * torch.sqrt(sig / dim)\n",
    "        svd_embed = torch.cat([svd_embed,svd_sigma],dim=1)\n",
    "\n",
    "    features = torch.FloatTensor(svd_embed)\n",
    "    features = features.unsqueeze(0)\n",
    "    \n",
    "    \n",
    "\n",
    "    if fixed:\n",
    "        embed, sigma, mu, loss = GraphNeuralNet(adj=adj, dim=dim, hidden=hidden, fixed=True, features=features, GNN=GNN1Layer)\n",
    "        return embed, sigma, mu, loss\n",
    "    else:\n",
    "        embed, mu, loss = GraphNeuralNet(adj=adj, dim=dim, hidden=hidden, fixed=False, features=features, GNN=GNN1Layer)\n",
    "        return embed, mu, loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HGNN_embed(adj,dim):\n",
    "    \n",
    "    print(\"\\nFixed Sigma dim {}\\n\".format(dim))\n",
    "    \n",
    "    lr,sig,fix_mu,fix_loss = HGNN(adj,dim,4,True)\n",
    "    \n",
    "    sigma = torch.ones(lr.shape).cuda() * torch.sqrt(sig/dim)\n",
    "    features = torch.cat([lr,sigma],dim=2).cpu().detach()\n",
    "    features = torch.Tensor(features)\n",
    "    \n",
    "\n",
    "    print(\"\\nFlexible Sigma dim {}\\n\".format(dim))\n",
    "    embed, flex_mu, flex_loss = GraphNeuralNet(adj=adj, dim=dim, hidden=4, fixed=False, features=features, GNN=GNN1Layer)\n",
    "    \n",
    "    print(\"\\n2 Layer dim {}\\n\".format(dim))\n",
    "    embed, flex_mu, flex_loss = GraphNeuralNet(adj=adj, dim=dim, hidden=4, fixed=False, features=embed.detach(), GNN=GNN2Layer)\n",
    "    \n",
    "    \n",
    "    return embed, fix_mu, flex_mu, fix_loss, flex_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fixed Sigma dim 1\n",
      "\n",
      "Epoch: 0001 loss: 10.95440483 time: 0.5421s\n",
      "Epoch: 5001 loss: 10.95440388 time: 0.0000s\n",
      "Epoch: 10001 loss: 10.95440388 time: 0.0099s\n",
      "Epoch: 15001 loss: 10.95440388 time: 0.0020s\n",
      "Epoch: 20001 loss: 10.95440388 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 48.8027s\n",
      "\n",
      "Flexible Sigma dim 1\n",
      "\n",
      "Epoch: 0001 loss: 10.95440388 time: 0.0020s\n",
      "Epoch: 5001 loss: 8.88333511 time: 0.0020s\n",
      "Epoch: 10001 loss: 8.83050346 time: 0.0010s\n",
      "Epoch: 15001 loss: 8.79169750 time: 0.0020s\n",
      "Epoch: 20001 loss: 8.68842697 time: 0.0010s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 31.4385s\n",
      "\n",
      "2 Layer dim 1\n",
      "\n",
      "Epoch: 0001 loss: 8.68842983 time: 0.0020s\n",
      "Epoch: 5001 loss: 8.53100014 time: 0.0020s\n",
      "Epoch: 10001 loss: 8.43688393 time: 0.0030s\n",
      "Epoch: 15001 loss: 8.33622456 time: 0.0020s\n",
      "Epoch: 20001 loss: 8.08775330 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 43.1034s\n",
      "\n",
      "Fixed Sigma dim 2\n",
      "\n",
      "Epoch: 0001 loss: 10.72826767 time: 0.0020s\n",
      "Epoch: 5001 loss: 10.72824192 time: 0.0020s\n",
      "Epoch: 10001 loss: 10.72824192 time: 0.0020s\n",
      "Epoch: 15001 loss: 10.72824192 time: 0.0020s\n",
      "Epoch: 20001 loss: 10.72824192 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 36.4917s\n",
      "\n",
      "Flexible Sigma dim 2\n",
      "\n",
      "Epoch: 0001 loss: 10.72824383 time: 0.0020s\n",
      "Epoch: 5001 loss: 8.42170143 time: 0.0020s\n",
      "Epoch: 10001 loss: 8.41810799 time: 0.0020s\n",
      "Epoch: 15001 loss: 8.40447903 time: 0.0010s\n",
      "Epoch: 20001 loss: 8.40447903 time: 0.0010s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 31.6095s\n",
      "\n",
      "2 Layer dim 2\n",
      "\n",
      "Epoch: 0001 loss: 8.40448093 time: 0.0030s\n",
      "Epoch: 5001 loss: 8.32457638 time: 0.0030s\n",
      "Epoch: 10001 loss: 8.18524742 time: 0.0020s\n",
      "Epoch: 15001 loss: 8.09815693 time: 0.0020s\n",
      "Epoch: 20001 loss: 7.92175055 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 43.0706s\n",
      "\n",
      "Fixed Sigma dim 3\n",
      "\n",
      "Epoch: 0001 loss: 10.41265488 time: 0.0020s\n",
      "Epoch: 5001 loss: 10.41125011 time: 0.0010s\n",
      "Epoch: 10001 loss: 10.41045761 time: 0.0020s\n",
      "Epoch: 15001 loss: 10.39734554 time: 0.0020s\n",
      "Epoch: 20001 loss: 10.39422512 time: 0.0010s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 37.1266s\n",
      "\n",
      "Flexible Sigma dim 3\n",
      "\n",
      "Epoch: 0001 loss: 10.39422512 time: 0.0020s\n",
      "Epoch: 5001 loss: 8.40829849 time: 0.0020s\n",
      "Epoch: 10001 loss: 8.38997555 time: 0.0020s\n",
      "Epoch: 15001 loss: 8.33268738 time: 0.0020s\n",
      "Epoch: 20001 loss: 8.20000744 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 31.9408s\n",
      "\n",
      "2 Layer dim 3\n",
      "\n",
      "Epoch: 0001 loss: 8.20001030 time: 0.0020s\n",
      "Epoch: 5001 loss: 8.18176556 time: 0.0020s\n",
      "Epoch: 10001 loss: 8.18176556 time: 0.0020s\n",
      "Epoch: 15001 loss: 8.18176556 time: 0.0020s\n",
      "Epoch: 20001 loss: 8.18176556 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 43.5864s\n",
      "\n",
      "Fixed Sigma dim 4\n",
      "\n",
      "Epoch: 0001 loss: 10.20869160 time: 0.0030s\n",
      "Epoch: 5001 loss: 10.19689655 time: 0.0020s\n",
      "Epoch: 10001 loss: 10.19371891 time: 0.0020s\n",
      "Epoch: 15001 loss: 10.19078827 time: 0.0020s\n",
      "Epoch: 20001 loss: 10.17027092 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 37.8318s\n",
      "\n",
      "Flexible Sigma dim 4\n",
      "\n",
      "Epoch: 0001 loss: 10.17027092 time: 0.0020s\n",
      "Epoch: 5001 loss: 8.26579571 time: 0.0010s\n",
      "Epoch: 10001 loss: 8.21456146 time: 0.0020s\n",
      "Epoch: 15001 loss: 8.10957432 time: 0.0020s\n",
      "Epoch: 20001 loss: 8.10957432 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 31.8943s\n",
      "\n",
      "2 Layer dim 4\n",
      "\n",
      "Epoch: 0001 loss: 8.10957432 time: 0.0020s\n",
      "Epoch: 5001 loss: 7.85039139 time: 0.0020s\n",
      "Epoch: 10001 loss: 7.68387699 time: 0.0020s\n",
      "Epoch: 15001 loss: 7.62310505 time: 0.0020s\n",
      "Epoch: 20001 loss: 7.62310505 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 43.0706s\n",
      "\n",
      "Fixed Sigma dim 5\n",
      "\n",
      "Epoch: 0001 loss: 10.08040905 time: 0.0030s\n",
      "Epoch: 5001 loss: 10.04469776 time: 0.0021s\n",
      "Epoch: 10001 loss: 10.03607368 time: 0.0020s\n",
      "Epoch: 15001 loss: 10.03070354 time: 0.0020s\n",
      "Epoch: 20001 loss: 10.02686501 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 39.1081s\n",
      "\n",
      "Flexible Sigma dim 5\n",
      "\n",
      "Epoch: 0001 loss: 10.02686691 time: 0.0020s\n",
      "Epoch: 5001 loss: 7.93080616 time: 0.0020s\n",
      "Epoch: 10001 loss: 7.92957830 time: 0.0020s\n",
      "Epoch: 15001 loss: 7.92957830 time: 0.0010s\n",
      "Epoch: 20001 loss: 7.92957830 time: 0.0010s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 33.3325s\n",
      "\n",
      "2 Layer dim 5\n",
      "\n",
      "Epoch: 0001 loss: 7.92957973 time: 0.0020s\n",
      "Epoch: 5001 loss: 7.48535442 time: 0.0020s\n",
      "Epoch: 10001 loss: 7.40924978 time: 0.0020s\n",
      "Epoch: 15001 loss: 7.37863159 time: 0.0020s\n",
      "Epoch: 20001 loss: 7.37863159 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 43.3184s\n",
      "\n",
      "Fixed Sigma dim 6\n",
      "\n",
      "Epoch: 0001 loss: 9.98619270 time: 0.0020s\n",
      "Epoch: 5001 loss: 9.97772121 time: 0.0020s\n",
      "Epoch: 10001 loss: 9.97578526 time: 0.0020s\n",
      "Epoch: 15001 loss: 9.97446060 time: 0.0020s\n",
      "Epoch: 20001 loss: 9.97348213 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 39.4369s\n",
      "\n",
      "Flexible Sigma dim 6\n",
      "\n",
      "Epoch: 0001 loss: 9.97348309 time: 0.0020s\n",
      "Epoch: 5001 loss: 7.88963318 time: 0.0020s\n",
      "Epoch: 10001 loss: 7.88728809 time: 0.0000s\n",
      "Epoch: 15001 loss: 7.88728809 time: 0.0000s\n",
      "Epoch: 20001 loss: 7.88728809 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 33.4188s\n",
      "\n",
      "2 Layer dim 6\n",
      "\n",
      "Epoch: 0001 loss: 7.88728476 time: 0.0010s\n",
      "Epoch: 5001 loss: 7.55623531 time: 0.0000s\n",
      "Epoch: 10001 loss: 7.46931362 time: 0.0030s\n",
      "Epoch: 15001 loss: 7.39876032 time: 0.0000s\n",
      "Epoch: 20001 loss: 7.33578253 time: 0.0000s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 42.9948s\n",
      "\n",
      "Fixed Sigma dim 7\n",
      "\n",
      "Epoch: 0001 loss: 9.89500713 time: 0.0000s\n",
      "Epoch: 5001 loss: 9.88209724 time: 0.0020s\n",
      "Epoch: 10001 loss: 9.87930584 time: 0.0020s\n",
      "Epoch: 15001 loss: 9.87551403 time: 0.0000s\n",
      "Epoch: 20001 loss: 9.87331581 time: 0.0021s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 39.6831s\n",
      "\n",
      "Flexible Sigma dim 7\n",
      "\n",
      "Epoch: 0001 loss: 9.87331581 time: 0.0000s\n",
      "Epoch: 5001 loss: 7.95667934 time: 0.0000s\n",
      "Epoch: 10001 loss: 7.95667934 time: 0.0010s\n",
      "Epoch: 15001 loss: 7.95667934 time: 0.0020s\n",
      "Epoch: 20001 loss: 7.95667934 time: 0.0000s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 33.7887s\n",
      "\n",
      "2 Layer dim 7\n",
      "\n",
      "Epoch: 0001 loss: 7.95667839 time: 0.0000s\n",
      "Epoch: 5001 loss: 7.29328251 time: 0.0020s\n",
      "Epoch: 10001 loss: 7.23634434 time: 0.0000s\n",
      "Epoch: 15001 loss: 7.23634434 time: 0.0000s\n",
      "Epoch: 20001 loss: 7.23634434 time: 0.0000s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 43.8084s\n",
      "\n",
      "Fixed Sigma dim 8\n",
      "\n",
      "Epoch: 0001 loss: 9.81505680 time: 0.0000s\n",
      "Epoch: 5001 loss: 9.80928040 time: 0.0030s\n",
      "Epoch: 10001 loss: 9.80666924 time: 0.0020s\n",
      "Epoch: 15001 loss: 9.80434895 time: 0.0020s\n",
      "Epoch: 20001 loss: 9.80237293 time: 0.0000s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 40.3209s\n",
      "\n",
      "Flexible Sigma dim 8\n",
      "\n",
      "Epoch: 0001 loss: 9.80237389 time: 0.0020s\n",
      "Epoch: 5001 loss: 7.90526533 time: 0.0000s\n",
      "Epoch: 10001 loss: 7.90526533 time: 0.0020s\n",
      "Epoch: 15001 loss: 7.90526533 time: 0.0000s\n",
      "Epoch: 20001 loss: 7.85064602 time: 0.0000s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 33.4923s\n",
      "\n",
      "2 Layer dim 8\n",
      "\n",
      "Epoch: 0001 loss: 7.85064983 time: 0.0000s\n",
      "Epoch: 5001 loss: 7.85064983 time: 0.0000s\n",
      "Epoch: 10001 loss: 7.85064983 time: 0.0020s\n",
      "Epoch: 15001 loss: 7.85064983 time: 0.0000s\n",
      "Epoch: 20001 loss: 7.85064983 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 47.6395s\n",
      "\n",
      "Fixed Sigma dim 9\n",
      "\n",
      "Epoch: 0001 loss: 9.73391914 time: 0.0111s\n",
      "Epoch: 5001 loss: 9.72719383 time: 0.0020s\n",
      "Epoch: 10001 loss: 9.72369385 time: 0.0020s\n",
      "Epoch: 15001 loss: 9.72091103 time: 0.0020s\n",
      "Epoch: 20001 loss: 9.71846581 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 41.0311s\n",
      "\n",
      "Flexible Sigma dim 9\n",
      "\n",
      "Epoch: 0001 loss: 9.71846581 time: 0.0000s\n",
      "Epoch: 5001 loss: 7.88542700 time: 0.0000s\n",
      "Epoch: 10001 loss: 7.88542700 time: 0.0000s\n",
      "Epoch: 15001 loss: 7.88542700 time: 0.0000s\n",
      "Epoch: 20001 loss: 7.72577620 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 33.9147s\n",
      "\n",
      "2 Layer dim 9\n",
      "\n",
      "Epoch: 0001 loss: 7.72577429 time: 0.0020s\n",
      "Epoch: 5001 loss: 7.67624140 time: 0.0000s\n",
      "Epoch: 10001 loss: 7.67624140 time: 0.0000s\n",
      "Epoch: 15001 loss: 7.67624140 time: 0.0000s\n",
      "Epoch: 20001 loss: 7.67624140 time: 0.0011s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 47.6980s\n",
      "\n",
      "Fixed Sigma dim 10\n",
      "\n",
      "Epoch: 0001 loss: 9.65957642 time: 0.0020s\n",
      "Epoch: 5001 loss: 9.65258121 time: 0.0091s\n",
      "Epoch: 10001 loss: 9.64965820 time: 0.0021s\n",
      "Epoch: 15001 loss: 9.64707851 time: 0.0000s\n",
      "Epoch: 20001 loss: 9.64509296 time: 0.0000s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 41.2638s\n",
      "\n",
      "Flexible Sigma dim 10\n",
      "\n",
      "Epoch: 0001 loss: 9.64509296 time: 0.0020s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5001 loss: 7.90142393 time: 0.0000s\n",
      "Epoch: 10001 loss: 7.90142393 time: 0.0020s\n",
      "Epoch: 15001 loss: 7.90142393 time: 0.0020s\n",
      "Epoch: 20001 loss: 7.90142393 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 34.3333s\n",
      "\n",
      "2 Layer dim 10\n",
      "\n",
      "Epoch: 0001 loss: 7.90142202 time: 0.0030s\n",
      "Epoch: 5001 loss: 7.90142202 time: 0.0020s\n",
      "Epoch: 10001 loss: 7.90142202 time: 0.0020s\n",
      "Epoch: 15001 loss: 7.88290310 time: 0.0030s\n",
      "Epoch: 20001 loss: 7.88290310 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 47.0455s\n",
      "\n",
      "Fixed Sigma dim 11\n",
      "\n",
      "Epoch: 0001 loss: 9.57401943 time: 0.0030s\n",
      "Epoch: 5001 loss: 9.56044197 time: 0.0020s\n",
      "Epoch: 10001 loss: 9.55696583 time: 0.0020s\n",
      "Epoch: 15001 loss: 9.55432034 time: 0.0020s\n",
      "Epoch: 20001 loss: 9.55202293 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 42.1306s\n",
      "\n",
      "Flexible Sigma dim 11\n",
      "\n",
      "Epoch: 0001 loss: 9.55202389 time: 0.0030s\n",
      "Epoch: 5001 loss: 7.76648808 time: 0.0020s\n",
      "Epoch: 10001 loss: 7.76648808 time: 0.0020s\n",
      "Epoch: 15001 loss: 7.76648808 time: 0.0010s\n",
      "Epoch: 20001 loss: 7.76648808 time: 0.0010s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 34.2145s\n",
      "\n",
      "2 Layer dim 11\n",
      "\n",
      "Epoch: 0001 loss: 7.76648617 time: 0.0030s\n",
      "Epoch: 5001 loss: 7.33072472 time: 0.0030s\n",
      "Epoch: 10001 loss: 7.33072472 time: 0.0030s\n",
      "Epoch: 15001 loss: 7.33072472 time: 0.0030s\n",
      "Epoch: 20001 loss: 7.33072472 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 46.8883s\n",
      "\n",
      "Fixed Sigma dim 12\n",
      "\n",
      "Epoch: 0001 loss: 9.52081776 time: 0.0030s\n",
      "Epoch: 5001 loss: 9.51592159 time: 0.0020s\n",
      "Epoch: 10001 loss: 9.51479816 time: 0.0020s\n",
      "Epoch: 15001 loss: 9.51395035 time: 0.0020s\n",
      "Epoch: 20001 loss: 9.51318645 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 42.0677s\n",
      "\n",
      "Flexible Sigma dim 12\n",
      "\n",
      "Epoch: 0001 loss: 9.51318645 time: 0.0020s\n",
      "Epoch: 5001 loss: 7.74488258 time: 0.0010s\n",
      "Epoch: 10001 loss: 7.74488258 time: 0.0020s\n",
      "Epoch: 15001 loss: 7.74488258 time: 0.0020s\n",
      "Epoch: 20001 loss: 7.74488258 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 34.3656s\n",
      "\n",
      "2 Layer dim 12\n",
      "\n",
      "Epoch: 0001 loss: 7.74488163 time: 0.0030s\n",
      "Epoch: 5001 loss: 7.74488163 time: 0.0030s\n",
      "Epoch: 10001 loss: 7.74488163 time: 0.0030s\n",
      "Epoch: 15001 loss: 7.74488163 time: 0.0020s\n",
      "Epoch: 20001 loss: 7.74488163 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 47.5179s\n",
      "\n",
      "Fixed Sigma dim 13\n",
      "\n",
      "Epoch: 0001 loss: 9.46569920 time: 0.0030s\n",
      "Epoch: 5001 loss: 9.46007729 time: 0.0020s\n",
      "Epoch: 10001 loss: 9.45889568 time: 0.0020s\n",
      "Epoch: 15001 loss: 9.45795536 time: 0.0020s\n",
      "Epoch: 20001 loss: 9.45711422 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 42.2452s\n",
      "\n",
      "Flexible Sigma dim 13\n",
      "\n",
      "Epoch: 0001 loss: 9.45711517 time: 0.0030s\n",
      "Epoch: 5001 loss: 7.65268087 time: 0.0020s\n",
      "Epoch: 10001 loss: 7.65268087 time: 0.0010s\n",
      "Epoch: 15001 loss: 7.65268087 time: 0.0020s\n",
      "Epoch: 20001 loss: 7.65268087 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 35.9581s\n",
      "\n",
      "2 Layer dim 13\n",
      "\n",
      "Epoch: 0001 loss: 7.65268087 time: 0.0030s\n",
      "Epoch: 5001 loss: 7.60854912 time: 0.0030s\n",
      "Epoch: 10001 loss: 7.57461309 time: 0.0030s\n",
      "Epoch: 15001 loss: 7.57461309 time: 0.0030s\n",
      "Epoch: 20001 loss: 7.57461309 time: 0.0030s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 52.8209s\n",
      "\n",
      "Fixed Sigma dim 14\n",
      "\n",
      "Epoch: 0001 loss: 9.40320015 time: 0.0020s\n",
      "Epoch: 5001 loss: 9.39410114 time: 0.0020s\n",
      "Epoch: 10001 loss: 9.39167118 time: 0.0020s\n",
      "Epoch: 15001 loss: 9.38985538 time: 0.0020s\n",
      "Epoch: 20001 loss: 9.38825607 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 42.7150s\n",
      "\n",
      "Flexible Sigma dim 14\n",
      "\n",
      "Epoch: 0001 loss: 9.38825703 time: 0.0030s\n",
      "Epoch: 5001 loss: 7.71185827 time: 0.0020s\n",
      "Epoch: 10001 loss: 7.71185827 time: 0.0020s\n",
      "Epoch: 15001 loss: 7.71185827 time: 0.0020s\n",
      "Epoch: 20001 loss: 7.71185827 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 34.6895s\n",
      "\n",
      "2 Layer dim 14\n",
      "\n",
      "Epoch: 0001 loss: 7.71185732 time: 0.0030s\n",
      "Epoch: 5001 loss: 7.71185732 time: 0.0030s\n",
      "Epoch: 10001 loss: 7.71185732 time: 0.0020s\n",
      "Epoch: 15001 loss: 7.51906204 time: 0.0020s\n",
      "Epoch: 20001 loss: 7.51906204 time: 0.0020s\n",
      "Optimization Finished!\n",
      "Total time elapsed: 47.9437s\n"
     ]
    }
   ],
   "source": [
    "fix_loss = []\n",
    "nonfix_loss = []\n",
    "svd_loss = []\n",
    "svdrelu_loss = []\n",
    "nmi_fix = []\n",
    "nmi_nonfix = []\n",
    "nmi_svd = []\n",
    "nmi_svdrelu = []\n",
    "dims = [x for x in range(1,15)]\n",
    "\n",
    "for dim in dims:\n",
    "    \n",
    "    fixembed, fix_mu, flex_mu, fixloss, flexloss = HGNN_embed(adj,dim)\n",
    "    fix_loss.append(fixloss)\n",
    "    nmi_fix.append(nmi_score(adj[0],fix_mu.reshape(adj.shape[1:]).cpu().detach()))\n",
    "    nonfix_loss.append(flexloss)\n",
    "    nmi_nonfix.append(nmi_score(adj[0],flex_mu.reshape(adj.shape[1:]).cpu().detach()))\n",
    "    \n",
    "    mu,sig,loss,embedx,embedy = svdApprox(adj=adj,dim=dim)\n",
    "    svd_loss.append(loss)\n",
    "    nmi_svd.append(nmi_score(adj[0],mu.reshape(adj.shape[1:]).cpu().detach()))\n",
    "    mu,sig,loss,embedx,embedy = svdApprox(adj=adj,dim=dim,relu=True)\n",
    "    svdrelu_loss.append(loss)\n",
    "    nmi_svdrelu.append(nmi_score(adj[0],mu.reshape(adj.shape[1:]).cpu().detach()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x238320b84c0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dims,fix_loss,label=\"Fixed Sigma\")\n",
    "plt.plot(dims,nonfix_loss,label=\"Flexible Sigma\")\n",
    "plt.plot(dims,svd_loss,label=\"SVD\")\n",
    "plt.plot(dims,svdrelu_loss,label=\"SVD Relu\")\n",
    "plt.xlabel(\"dim\")\n",
    "plt.ylabel(\"NLL\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
